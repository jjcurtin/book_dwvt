{
  "hash": "37f52cbfa3a46d08cd12a240298e0b00",
  "result": {
    "engine": "knitr",
    "markdown": "---\noutput: html_document\neditor_options: \n  chunk_output_type: console\n---\n\n\n# Simulations\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n:::\n\n\n## The Components of a Simulation\n\n### Setting up Xs (exogenous variables)\n\nTypically use `mvrnorm()` in the MASS package to produces a set of $X$ that have some specified population means, variances, and covariances.  In our example, we will simulate 3 variables with differing means, variances = 1, and covariances = 0.  Of course, you could do whatever you need here.\n\n- Specify population means \n\n::: {.cell}\n\n```{.r .cell-code}\nmeans <- c(4, 6, 10)\n```\n:::\n\n\n- Variance/covariance matrix.  Can do this with uncorrelated Xs with variances of 1 using `diag()`.  Or can specific specific variances and covariances\n\n::: {.cell}\n\n```{.r .cell-code}\nsigma <- diag(3) \n\nsigma\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     [,1] [,2] [,3]\n[1,]    1    0    0\n[2,]    0    1    0\n[3,]    0    0    1\n```\n\n\n:::\n:::\n\n\n- Here we demonstrate use of matrix for specific sigma (but with same values as above)\n\n::: {.cell}\n\n```{.r .cell-code}\nsigma <- matrix(c(1, 0, 0, \n                  0, 1, 0, \n                  0, 0, 1), \n                nrow = 3, byrow = TRUE) \n```\n:::\n\n\nNow we can generate data for a specific $N$ (in this case, 1000)\n\n::: {.cell}\n\n```{.r .cell-code}\nn_obs <- 1000\nx <- MASS::mvrnorm(n = n_obs, mu = means, Sigma = sigma) |>  \n    magrittr::set_colnames(str_c(\"x\", 1:length(means))) |>  \n    as_tibble() \n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nx |> head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 3\n     x1    x2    x3\n  <dbl> <dbl> <dbl>\n1  1.56  4.94 10.1 \n2  5.47  5.79 10.1 \n3  4.03  5.09  8.73\n4  3.08  4.95  8.87\n5  2.64  5.38  9.15\n6  4.21  4.64 10.6 \n```\n\n\n:::\n\n```{.r .cell-code}\nx |> summarize(across(everything(), list(mean = mean, var = var)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 6\n  x1_mean x1_var x2_mean x2_var x3_mean x3_var\n    <dbl>  <dbl>   <dbl>  <dbl>   <dbl>  <dbl>\n1    3.97   1.08    6.05  0.990    9.99   1.03\n```\n\n\n:::\n\n```{.r .cell-code}\ncor(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            x1          x2          x3\nx1  1.00000000 -0.02275581  0.01003546\nx2 -0.02275581  1.00000000 -0.03139993\nx3  0.01003546 -0.03139993  1.00000000\n```\n\n\n:::\n:::\n\n\n### Defining a Data Generating Process (DGP) for a Quantitative Y\n\nWe start with dataframe $x$\n\n- Add an intercept as first column\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- x |> \n  mutate(x0 = 1) |> \n  relocate(x0)\n\nhead(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 4\n     x0    x1    x2    x3\n  <dbl> <dbl> <dbl> <dbl>\n1     1  1.56  4.94 10.1 \n2     1  5.47  5.79 10.1 \n3     1  4.03  5.09  8.73\n4     1  3.08  4.95  8.87\n5     1  2.64  5.38  9.15\n6     1  4.21  4.64 10.6 \n```\n\n\n:::\n:::\n\n\n- Set parameter estimates.  This includes $b_0$ as the first entry\n\n::: {.cell}\n\n```{.r .cell-code}\nb <- c(100, 2, 5, 1)\n```\n:::\n\n\n- Set standard deviation of error\n\n::: {.cell}\n\n```{.r .cell-code}\ne <- 10\n```\n:::\n\n\n- Calculate Y and put it all in a dataframe\n\n::: {.cell}\n\n```{.r .cell-code}\nd <- x |> \n  mutate(y = rowSums(t(t(x)*b)) + rnorm(n_obs, \n                                        mean = 0, \n                                        sd = e))\n\nhead(d)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 5\n     x0    x1    x2    x3     y\n  <dbl> <dbl> <dbl> <dbl> <dbl>\n1     1  1.56  4.94 10.1   151.\n2     1  5.47  5.79 10.1   137.\n3     1  4.03  5.09  8.73  131.\n4     1  3.08  4.95  8.87  133.\n5     1  2.64  5.38  9.15  135.\n6     1  4.21  4.64 10.6   138.\n```\n\n\n:::\n:::\n\n\n### Wrap it all in a function\n\n\n::: {.cell}\n\n```{.r .cell-code}\nget_data <- function(s, n_obs, means, sigma, b, e) {\n  \n  x <- MASS::mvrnorm(n = n_obs, mu = means, Sigma = sigma) |>  \n    magrittr::set_colnames(str_c(\"x\", 1:length(means))) |>  \n    as_tibble() |> \n    mutate(x0 = 1) |> \n    relocate(x0)\n  \n  x |> \n    mutate(y = rowSums(t(t(x)*b)) + rnorm(n_obs, 0, e)) |> \n    mutate(s = s) |> \n    relocate(s)\n}\n```\n:::\n\n\nNow we can use this function to simulate a data set with any properties\n\n::: {.cell}\n\n```{.r .cell-code}\nget_data(1,\n         n_obs <- 1000,\n         means <- c(4, 6, 10), \n         sigma <- diag(3),\n         b <- c(100, 2, 5, 1),\n         e <- 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1,000 × 6\n       s    x0    x1    x2    x3     y\n   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n 1     1     1  3.73  3.98 10.5   138.\n 2     1     1  4.30  6.66  8.49  152.\n 3     1     1  5.08  6.03  9.95  158.\n 4     1     1  4.32  4.21  6.69  135.\n 5     1     1  3.86  5.59  9.12  143.\n 6     1     1  4.81  6.00 10.6   150.\n 7     1     1  3.26  5.22  9.14  137.\n 8     1     1  3.95  7.07 10.5   136.\n 9     1     1  2.40  7.35 10.9   146.\n10     1     1  3.93  3.76  9.80  140.\n# ℹ 990 more rows\n```\n\n\n:::\n:::\n\n\n### Iterate over simulations\n\nLets pretend we want 100 simulated datasets\n\n- It is important to set a seed to make these datasets reproducible\n- We can use map (or `future_map()`) to iterate over `get_data()`\n- We can use list columns for this so we get a dataframe with rows for each simulated dataset and the full dataset for each entry for the `data` column\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn_sims <- 100  # this would generally be much higher!\n\nn_obs <- 1000\nmeans <- c(4, 6, 10)\nsigma <- diag(3)\nb <- c(100, 2, 5, 1)\ne <- 10\n\nsims <- 1:n_sims |> \n  map(\\(s) get_data(s, n_obs, means, sigma, b, e)) |> \n  list_rbind() |> \n  nest(.by = s,\n       .key = \"data\")\n\nhead(sims)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 2\n      s data                \n  <int> <list>              \n1     1 <tibble [1,000 × 5]>\n2     2 <tibble [1,000 × 5]>\n3     3 <tibble [1,000 × 5]>\n4     4 <tibble [1,000 × 5]>\n5     5 <tibble [1,000 × 5]>\n6     6 <tibble [1,000 × 5]>\n```\n\n\n:::\n:::\n\n\nWe can now use this df with list columns to calculate whatever we are testing for our simulation.  \n\nIn this trivial example, lets show that the parameter estimate for $x_1$ matches what we set.  We will also use list columns to store intermedidate results (e.g., the lm)\n\n- write function to use our simulated data to estimate $b_1$ (Note that we could have used an anonymous function for this, but I think its cleaner to have a named function)\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_lm <- function(d){\n  lm(y ~ x1 + x2 + x3, data = d) \n}\n```\n:::\n\n\n- Now fit this model for each simulated dataset and save model in list column\n- Notice we now have a column that stores these models\n\n::: {.cell}\n\n```{.r .cell-code}\nsims <- sims |> \n  mutate(model = map(data, fit_lm))\n\nhead(sims)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 3\n      s data                 model \n  <int> <list>               <list>\n1     1 <tibble [1,000 × 5]> <lm>  \n2     2 <tibble [1,000 × 5]> <lm>  \n3     3 <tibble [1,000 × 5]> <lm>  \n4     4 <tibble [1,000 × 5]> <lm>  \n5     5 <tibble [1,000 × 5]> <lm>  \n6     6 <tibble [1,000 × 5]> <lm>  \n```\n\n\n:::\n:::\n\n\nNow lets extract $b_1$ from the models and save in their own column.  We can write a function for this and use `broom::tidy()`\n\n::: {.cell}\n\n```{.r .cell-code}\nget_b1 <- function(model){\n model |> \n    broom::tidy() |> \n    filter(term == \"x1\") |> \n    pull(estimate)\n}\n\nsims <- sims |> \n  mutate(b1 = map(model, get_b1))\n\nhead(sims)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 4\n      s data                 model  b1       \n  <int> <list>               <list> <list>   \n1     1 <tibble [1,000 × 5]> <lm>   <dbl [1]>\n2     2 <tibble [1,000 × 5]> <lm>   <dbl [1]>\n3     3 <tibble [1,000 × 5]> <lm>   <dbl [1]>\n4     4 <tibble [1,000 × 5]> <lm>   <dbl [1]>\n5     5 <tibble [1,000 × 5]> <lm>   <dbl [1]>\n6     6 <tibble [1,000 × 5]> <lm>   <dbl [1]>\n```\n\n\n:::\n:::\n\n\nNow we can unnest the column for `b1` and do analyses.  Of course, we could unnest other columns if we needed access to the simuated data or the linear models we fit\n\n::: {.cell}\n\n```{.r .cell-code}\nsims <- sims |> \n  unnest(b1)\n\nhead(sims)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 4\n      s data                 model     b1\n  <int> <list>               <list> <dbl>\n1     1 <tibble [1,000 × 5]> <lm>    1.67\n2     2 <tibble [1,000 × 5]> <lm>    1.69\n3     3 <tibble [1,000 × 5]> <lm>    1.91\n4     4 <tibble [1,000 × 5]> <lm>    2.17\n5     5 <tibble [1,000 × 5]> <lm>    2.20\n6     6 <tibble [1,000 × 5]> <lm>    2.13\n```\n\n\n:::\n\n```{.r .cell-code}\n# mean and standard error of sampling distribution\nsims |> \n  summarize(mean = mean(b1), sd = sd(b1))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 2\n   mean    sd\n  <dbl> <dbl>\n1  2.01 0.310\n```\n\n\n:::\n\n```{.r .cell-code}\n# plot of the sampling distribution\nsims |> \n  ggplot(data = sims,\n         mapping = aes(x = b1)) + \n  geom_histogram(bins  = 30)\n```\n\n::: {.cell-output-display}\n![](simulations_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\n\n## Other Extensions and Loose Ends\n\n### Binary Y\n\nIn the example above, we simulated a quantitative Y that was a linear function of 3 Xs.   Often, we need to simulate binary outcomes.  This is easy too.\n\n- We typically simulate binary outcomes using the logistic function. You could use other functional forms but this one works well for most our needs.\n\n- We can use our same X\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 4\n     x0    x1    x2    x3\n  <dbl> <dbl> <dbl> <dbl>\n1     1  1.56  4.94 10.1 \n2     1  5.47  5.79 10.1 \n3     1  4.03  5.09  8.73\n4     1  3.08  4.95  8.87\n5     1  2.64  5.38  9.15\n6     1  4.21  4.64 10.6 \n```\n\n\n:::\n:::\n\n\n- But now the DGP for Y is different.  First we need to calculate the probability of the positive class as a function of X\n\n::: {.cell}\n\n```{.r .cell-code}\ncalc_p <- function(d, b0, b1, b2, b3){\n exp(b0 + b1*x$x1 + b2*x$x2 + b3*x$x3) /\n   (1 + exp(b0 + b1*x$x1 + b2*x$x2 + b3*x$x3))\n}\n```\n:::\n\n\n- Now we can apply this over the rows of d\n\n::: {.cell}\n\n```{.r .cell-code}\nd <- x |> \n  mutate(p = calc_p(x, 1,2,3,4))\n\nhead(d)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 5\n     x0    x1    x2    x3     p\n  <dbl> <dbl> <dbl> <dbl> <dbl>\n1     1  1.56  4.94 10.1      1\n2     1  5.47  5.79 10.1      1\n3     1  4.03  5.09  8.73     1\n4     1  3.08  4.95  8.87     1\n5     1  2.64  5.38  9.15     1\n6     1  4.21  4.64 10.6      1\n```\n\n\n:::\n:::\n\n\n- And now we can use the binomial distribution to get binary outcome based on these probabilities\n\n::: {.cell}\n\n```{.r .cell-code}\nd <- d |> \n  mutate(y = rbinom(1000,1,p))\n\nhead(d)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 6\n     x0    x1    x2    x3     p     y\n  <dbl> <dbl> <dbl> <dbl> <dbl> <int>\n1     1  1.56  4.94 10.1      1     1\n2     1  5.47  5.79 10.1      1     1\n3     1  4.03  5.09  8.73     1     1\n4     1  3.08  4.95  8.87     1     1\n5     1  2.64  5.38  9.15     1     1\n6     1  4.21  4.64 10.6      1     1\n```\n\n\n:::\n:::\n\n\n- And of course, we can wrap this all up into one function to simulate these data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nget_binary_data <- function(s, n_obs, means, sigma, b) {\n  \n  x <- MASS::mvrnorm(n = n_obs, mu = means, Sigma = sigma) |>  \n    magrittr::set_colnames(str_c(\"x\", 1:length(means))) |>  \n    as_tibble() |> \n    mutate(x0 = 1) |> \n    relocate(x0)\n  \n  calc_p <- function(x, b){\n   exp(b[1] + b[2]*x$x1 + b[3]*x$x2 + b[4]*x$x3) /\n     (1 + exp(b[1] + b[2]*x$x1 + b[3]*x$x2 + b[4]*x$x3))\n  } \n  \n  x |> \n    mutate(p = calc_p(x, b)) |> \n    mutate(y = rbinom(nrow(x), 1, p))  \n}\n```\n:::\n\n\nFrom here, you can now pick up as before for the quantitative example\n\n### Fixing the variance of Y to set value\n\n- insert notes from markus\n- Talk with markus about need for scaled Y and possible use of mvrnorm() for all variables\n\n### Converting between correlation and covariance matrices\n\n`MASS::mvrnorm()` takes sigma (the variance/covariance matrix).  Sometimes, we might want to think in terms of correlations.  \n\nHere is a function to convert a correlation matrix to a variance/covariance matrix\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncor2cov <- function (r, sd){\n  diag(sd) %*% r %*% diag(sd)\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nr <- matrix(c(1.0, 0.4, 0.3,\n              0.4, 1.0, 0.5,\n              0.3, 0.5, 1.0),\n            nrow = 3, byrow = TRUE)\n\nsd <- c(5, 10, 2)\n\ncor2cov(r, sd)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     [,1] [,2] [,3]\n[1,]   25   20    3\n[2,]   20  100   10\n[3,]    3   10    4\n```\n\n\n:::\n:::",
    "supporting": [
      "simulations_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}