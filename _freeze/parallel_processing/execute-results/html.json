{
  "hash": "0fad13618c63edff58fb95b38295b107",
  "result": {
    "engine": "knitr",
    "markdown": "---\neditor_options: \n  chunk_output_type: console\n---\n\n\n## Parallel Processing\n\n## TLDR\n\nTo set up, start and end parallel processing for either `tidymodels` or `future_map()` use the following code:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(future) # include among other packages that you load at top of script\n\n# set plan when ready to begin parallel processing.  \nplan(multisession, workers = parallel::detectCores(logical = FALSE))\n\n#\n# do your parallel processing here\n#\n\n# end parallel processing when done  \nplan(sequential) \n```\n:::\n\n\nFor parallel processing with `foreach()`, you also need to load the `doFuture` package and use `%dofuture%` instead of `%do%` or `%dopar%` in your `foreach()` code chunk.  The same plan setup and ending is used as for `future_map()`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(future) # include among other packages that you load at top of script\nlibrary(doFuture) \n\n# set plan when ready to begin parallel processing.  \nplan(multisession, workers = parallel::detectCores(logical = FALSE))\n\n# an example foreach loop in parallel mode\nx <- foreach(time = c(2, 2, 2), .combine = \"c\") %dofuture% {\n  Sys.sleep(time)\n  time\n}\n\n\n# end parallel processing when done  \nplan(sequential) \n```\n:::\n\n\n## Some introductory notes\n\nThe [furrr](https://cran.r-project.org/web/packages/furrr/index.html) package provides a parallel version of the map functions for iteration.   The developers provide useful [documentation and deep dives](https://furrr.futureverse.org/) that are worth reading when you start using `future_map()` and its variants.\n\n[foreach](https://cran.r-project.org/web/packages/foreach/vignettes/foreach.html) provides an alternative for loop that can run sequentially or in parallel as requested.  Previously, `foreach` was used under the hood to do resampling by `fit_resamples()` and `tune_grid()` in tidymodels.  However, this has been replaced by the same backend used by furrr (future) as of tune 1.2.1.\n\nMichael Hallquist has provided a useful and detailed [overview](https://psu-psychology.github.io/r-bootcamp-2018/talks/parallel_r.html) of parallel processing.   It is a good first read to orient to terms and concepts.  However, it does not describe either the `future` package or the `furrr` package.  It does provide brief introduction to `foreach`\n\n[Info on future ecosystem](https://dcgerard.github.io/advancedr/09_future.html) and [more](https://cran.r-project.org/web/packages/future/vignettes/future-3-topologies.html)\n\nAlso see documentation on parallel processing in tidymodels\n\n- [Parallel processing and other optimizations](https://tune.tidymodels.org/articles/extras/optimizations.html)\n- Help in R: `?tune::parallelism()`\n\n\n## Begin test bed to comfirm that this code works as expected.\n\nFirst set up code for `tidymodels/tidyverse`, packages for parallel processing and then specific packages for timing code, `future_map()` and `foreach()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(tidymodels)\n\n# for setting up parallel processing plans for tidymodels and other parallel workflows\nlibrary(future)  \n# for foreach() parallel processing with future backend\nlibrary(doFuture) \n\nlibrary(tictoc)  # for crude timing to evaluate benefits\nlibrary(furrr) # for future_map()\nlibrary(foreach, exclude = c(\"accumulate\", \"when\")) # for foreach()\n\n# source for demo ML workflow in tidymodels\nsource(\"https://github.com/jjcurtin/lab_support/blob/main/fun_ml.R?raw=true\")\n```\n:::\n\n\n\n\n### future_map()\n\nHere is the use of map (from purrr) that uses sequential processing\n\n::: {.cell}\n\n```{.r .cell-code}\ntic()\nx <- map(c(2, 2, 2), \\(time) Sys.sleep(time))\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n6.014 sec elapsed\n```\n\n\n:::\n:::\n\n\n\nUsing `future_map()` with a plan\n\n::: {.cell}\n\n```{.r .cell-code}\n# library(future)  # need this loaded at top of script to use plan()\n\n# using detectCores from parallel package to set number of workers to number of physical cores on machine.  You may want to set this to a lower number if you want to leave some cores free for other tasks.\nplan(multisession, workers = parallel::detectCores(logical = FALSE))\n\ntic()\nx <- future_map(c(2, 2, 2), \\(time) Sys.sleep(time))\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n2.558 sec elapsed\n```\n\n\n:::\n\n```{.r .cell-code}\nplan(sequential)\n```\n:::\n\n\n\n\n## tune_grid() in tidymodels\n\nSet up data, resamples, recipe, tuning grid. Will do 3x 10-fold CV to tune an ElasticNet glm with a sample size of 1000 and 30 features\n\n::: {.cell}\n\n```{.r .cell-code}\n# set up data\nn_obs <- 1000\nn_x <- 30\nirr_err <- 5\nd <- MASS::mvrnorm(n = n_obs, mu = rep(0,n_x), Sigma = diag(n_x)) %>% \n    magrittr::set_colnames(str_c(\"x\", 1:n_x)) %>% \n    as_tibble() %>% \n    mutate(error = rnorm(n_obs, 0, irr_err),\n           y = rowSums(across(everything()))) %>% \n    select(-error)\n\n# recipe\nrec <- recipe(y ~ ., data = d)\n\n# 10-fold CV\nset.seed(19690127)\nsplits <- d %>% \n  vfold_cv(v = 10, strata = \"y\")\n\n# tuning grid\ntune_grid <- expand_grid(penalty = exp(seq(0, 6, length.out = 200)),\n                           mixture = seq(0, 1, length.out = 11))\n```\n:::\n\n\nFirst, let's benchmark without parallel processing.  `tune_grid()` (and `fit_resamples()`) default is to allow parallel processing if it is available.   Since our  plan is currently set to sequential, this code will not use parallel processing.  Note that you ccan also not use parallel processing in tidymodel functions by using `control_grid()`.  I've left that code below in comments in case ever needed.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntic()\nlinear_reg(penalty = tune(), mixture = tune()) %>% \n  set_engine(\"glmnet\") %>% \n  tune_grid(preprocessor = rec, \n            # control = control_grid(allow_par = FALSE), # turn off pp\n            resamples = splits, grid = tune_grid, \n            metrics = metric_set(rmse))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Tuning results\n# 10-fold cross-validation using stratification \n# A tibble: 10 × 4\n   splits            id     .metrics             .notes          \n   <list>            <chr>  <list>               <list>          \n 1 <split [900/100]> Fold01 <tibble [2,200 × 6]> <tibble [0 × 4]>\n 2 <split [900/100]> Fold02 <tibble [2,200 × 6]> <tibble [0 × 4]>\n 3 <split [900/100]> Fold03 <tibble [2,200 × 6]> <tibble [0 × 4]>\n 4 <split [900/100]> Fold04 <tibble [2,200 × 6]> <tibble [0 × 4]>\n 5 <split [900/100]> Fold05 <tibble [2,200 × 6]> <tibble [0 × 4]>\n 6 <split [900/100]> Fold06 <tibble [2,200 × 6]> <tibble [0 × 4]>\n 7 <split [900/100]> Fold07 <tibble [2,200 × 6]> <tibble [0 × 4]>\n 8 <split [900/100]> Fold08 <tibble [2,200 × 6]> <tibble [0 × 4]>\n 9 <split [900/100]> Fold09 <tibble [2,200 × 6]> <tibble [0 × 4]>\n10 <split [900/100]> Fold10 <tibble [2,200 × 6]> <tibble [0 × 4]>\n```\n\n\n:::\n\n```{.r .cell-code}\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n1523.651 sec elapsed\n```\n\n\n:::\n:::\n\n\n\nNow  we set up a parallel plan (multisession) and run again.\n\n::: {.cell}\n\n```{.r .cell-code}\n# library(future)  # need this loaded at top of script to use plan()\nplan(multisession, workers = parallel::detectCores(logical = FALSE))\n\ntic()\nlinear_reg(penalty = tune(), mixture = tune()) %>% \n  set_engine(\"glmnet\") %>% \n  tune_grid(preprocessor = rec, \n            resamples = splits, grid = tune_grid, \n            metrics = metric_set(rmse))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Tuning results\n# 10-fold cross-validation using stratification \n# A tibble: 10 × 4\n   splits            id     .metrics             .notes          \n   <list>            <chr>  <list>               <list>          \n 1 <split [900/100]> Fold01 <tibble [2,200 × 6]> <tibble [0 × 4]>\n 2 <split [900/100]> Fold02 <tibble [2,200 × 6]> <tibble [0 × 4]>\n 3 <split [900/100]> Fold03 <tibble [2,200 × 6]> <tibble [0 × 4]>\n 4 <split [900/100]> Fold04 <tibble [2,200 × 6]> <tibble [0 × 4]>\n 5 <split [900/100]> Fold05 <tibble [2,200 × 6]> <tibble [0 × 4]>\n 6 <split [900/100]> Fold06 <tibble [2,200 × 6]> <tibble [0 × 4]>\n 7 <split [900/100]> Fold07 <tibble [2,200 × 6]> <tibble [0 × 4]>\n 8 <split [900/100]> Fold08 <tibble [2,200 × 6]> <tibble [0 × 4]>\n 9 <split [900/100]> Fold09 <tibble [2,200 × 6]> <tibble [0 × 4]>\n10 <split [900/100]> Fold10 <tibble [2,200 × 6]> <tibble [0 × 4]>\n```\n\n\n:::\n\n```{.r .cell-code}\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n207.339 sec elapsed\n```\n\n\n:::\n\n```{.r .cell-code}\nplan(sequential)\n```\n:::\n\n\n\n### foreach()\n\n`foreach()`  can run natively in sequential mode using `%do%`\n\n::: {.cell}\n\n```{.r .cell-code}\ntic()\nx <- foreach(time = c(2, 2, 2), .combine = \"c\") %do% {\n  Sys.sleep(time)\n  time\n}\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n6.02 sec elapsed\n```\n\n\n:::\n:::\n\n\n\n`foreach90` supports parallel processing with the future backend like future_map and tidymodels functions.   However, there are two additiona adjustments needed:\n\n- The `doFuture` is needed. \n- and `%dofuture%` replaces `%do%` (or the previously used `%dopar%`) to run code in parallel.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# library(future)  # need this loaded at top of script to use plan as before\nlibrary(doFuture) # also need doFuture to use %dofuture% with foreach()\n\nplan(multisession, workers = parallel::detectCores(logical = FALSE))\n\ntic()\nx <- foreach(time = c(2, 2, 2), .combine = \"c\") %dofuture% {\n  Sys.sleep(time)\n  time\n}\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n2.394 sec elapsed\n```\n\n\n:::\n\n```{.r .cell-code}\nplan(sequential)\n```\n:::\n\n\n\nThere are some nuances about using random numbers inside of `foreach()` loops in parallel. I still need a demo on this.   There is some discussion of `doFuture` handling this better natively.  I have also read that `%dorng%` is recommended but this may be dated. \n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(20140102)\nx <- foreach(time = c(2, 2, 2), .combine = \"c\") %dofuture% {\n  Sys.sleep(time)\n  rnorm(1)\n}\nprint(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.6978376  0.4016699 -0.4128653\n```\n\n\n:::\n\n```{.r .cell-code}\n# reproducible?\nset.seed(20140102)\nx <- foreach(time = c(2, 2, 2), .combine = \"c\") %dofuture% {\n  Sys.sleep(time)\n  rnorm(1)\n}\nprint(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.6978376  0.4016699 -0.4128653\n```\n\n\n:::\n:::",
    "supporting": [
      "parallel_processing_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}