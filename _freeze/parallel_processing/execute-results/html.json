{
  "hash": "9ce9ce337fd72e416c9c822fab07da74",
  "result": {
    "engine": "knitr",
    "markdown": "---\noutput: html_document\neditor_options: \n  chunk_output_type: console\n---\n\n# Parallel Processing\n\n\n::: {.cell}\n\n:::\n\n\nThe [furrr](https://cran.r-project.org/web/packages/furrr/index.html) package provides a parallel version of the map functions for iteration.   The developers provide useful [documentation and deep dives](https://furrr.futureverse.org/) that are worth reading when you start using `future_map()` and its variants.\n\n[foreach](https://cran.r-project.org/web/packages/foreach/vignettes/foreach.html) provides an alternative for loop that can run sequentially or in parallel as requested.  `foreach` is used under the hood to do resampling by `fit_resamples()` and `tune_grid()` in tidymodels\n\nMichael Hallquist has provided a useful and detailed [overview](https://psu-psychology.github.io/r-bootcamp-2018/talks/parallel_r.html) of parallel processing.   It is a good first read to orient to terms and concepts.  However, it does not describe either the `future` package or the `furrr` package.  It does provide brief introduction to `foreach`\n\n[Info on future ecosystem](https://dcgerard.github.io/advancedr/09_future.html) and [more](https://cran.r-project.org/web/packages/future/vignettes/future-3-topologies.html)\n\n[Parallel processing and other optimizations](https://tune.tidymodels.org/articles/extras/optimizations.html) in tidymodels\n\n\nHere are the number of physical (not logical) cores on this machine.  You may have more or less\n\n::: {.cell}\n\n```{.r .cell-code}\nparallel::detectCores(logical = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 40\n```\n\n\n:::\n:::\n\n\nLets use them by setting up a parallel backend.  \n\n- This works on Windows, Mac OSs, and Linux.  \n- Options that use forking rather than sockets may be [faster](https://www.r-bloggers.com/2019/06/parallel-r-socket-or-fork/) for Linux and Mac OSs but we prefer sockets because it works on all three major OSs and we use all three in our lab.\n- We prefer to use namespace when calling these functions rather than loading full packages\n\n::: {.cell}\n\n```{.r .cell-code}\ncl <- parallel::makePSOCKcluster(parallel::detectCores(logical = FALSE))\ndoParallel::registerDoParallel(cl)\n```\n:::\n\n\n\n### future_map()\n\nHere is the use of map (that uses sequential processing)\n\n::: {.cell}\n\n```{.r .cell-code}\ntic()\nx <- map(c(2, 2, 2), \\(time) Sys.sleep(time))\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n6.015 sec elapsed\n```\n\n\n:::\n:::\n\n\nUsing `future_map()` without a plan (Don't do this!)\n\n::: {.cell}\n\n```{.r .cell-code}\ntic()\nx <- future_map(c(2, 2, 2), \\(time) Sys.sleep(time))\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n6.082 sec elapsed\n```\n\n\n:::\n:::\n\n\nUsing `future_map()` with a plan (Do this!)\n\n::: {.cell}\n\n```{.r .cell-code}\nplan(multisession, workers = parallel::detectCores(logical = FALSE))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntic()\nx <- future_map(c(2, 2, 2), \\(time) Sys.sleep(time))\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n3.977 sec elapsed\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplan(sequential)\n```\n:::\n\n\n\n### foreach()\n\n`foreach()` in sequential mode using `%do%`\n\n::: {.cell}\n\n```{.r .cell-code}\ntic()\nx <- foreach(time = c(2, 2, 2), .combine = \"c\") %do% {\n  Sys.sleep(time)\n  time\n}\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n6.019 sec elapsed\n```\n\n\n:::\n:::\n\n\n`foreach()` in parallel mode using `%dopar%` but without a plan.  in contrast to `future_map()`, no plan is needed for `foreach()`.  You should use it without a plan!\n\n::: {.cell}\n\n```{.r .cell-code}\ntic()\nx <- foreach(time = c(2, 2, 2), .combine = \"c\") %dopar% {\n  Sys.sleep(time)\n  time\n}\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n2.078 sec elapsed\n```\n\n\n:::\n:::\n\n\nBut a plan doesn't break anything either  Still, don't use it because not needed.\n\n::: {.cell}\n\n```{.r .cell-code}\nplan(multisession, workers = parallel::detectCores(logical = FALSE))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntic()\nx <- foreach(time = c(2, 2, 2), .combine = \"c\") %dopar% {\n  Sys.sleep(time)\n  time\n}\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n2.062 sec elapsed\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplan(sequential)\n```\n:::\n\n\nNeed a demo for how to handle random numbers. No error or warning here but `%dorng%` is recommended I think?\n\n::: {.cell}\n\n```{.r .cell-code}\ntic()\nx <- foreach(time = c(2, 2, 2), .combine = \"c\") %dopar% {\n  Sys.sleep(time)\n  rnorm(1)\n}\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n2.08 sec elapsed\n```\n\n\n:::\n:::\n\n\n## tune_grid() in tidymodels\n\nSet up data, resamples, recipe, tuning grid. Will do 3x 10-fold CV to tune an elasticnet glm with a sample size of 1000 and 30 features\n\n::: {.cell}\n\n```{.r .cell-code}\n# set up data\nn_obs <- 1000\nn_x <- 30\nirr_err <- 5\nd <- MASS::mvrnorm(n = n_obs, mu = rep(0,n_x), Sigma = diag(n_x)) %>% \n    magrittr::set_colnames(str_c(\"x\", 1:n_x)) %>% \n    as_tibble() %>% \n    mutate(error = rnorm(n_obs, 0, irr_err),\n           y = rowSums(across(everything()))) %>% \n    select(-error)\n\n# recipe\nrec <- recipe(y ~ ., data = d)\n\n# 10-fold CV\nset.seed(19690127)\nsplits <- d %>% \n  vfold_cv(v = 10, strata = \"y\")\n\n# tuning grid\ntune_grid <- expand_grid(penalty = exp(seq(0, 6, length.out = 200)),\n                           mixture = seq(0, 1, length.out = 11))\n```\n:::\n\n\nFirst, let's benchmark without parallel processing.  `tune_grid()` (and `fit_resamples()`) default is to allow parallel processing so have to explicitly turn it off using `control_grid()`.  You will NOT do this.  It is only to show the benefits of parallel processing.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntic()\nlinear_reg(penalty = tune(), mixture = tune()) %>% \n  set_engine(\"glmnet\") %>% \n  tune_grid(preprocessor = rec, \n            resamples = splits, grid = tune_grid, \n            metrics = metric_set(rmse),\n            control = control_grid(allow_par = FALSE)) # turn off pp\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Tuning results\n# 10-fold cross-validation using stratification \n# A tibble: 10 × 4\n   splits            id     .metrics             .notes          \n   <list>            <chr>  <list>               <list>          \n 1 <split [900/100]> Fold01 <tibble [2,200 × 6]> <tibble [0 × 3]>\n 2 <split [900/100]> Fold02 <tibble [2,200 × 6]> <tibble [0 × 3]>\n 3 <split [900/100]> Fold03 <tibble [2,200 × 6]> <tibble [0 × 3]>\n 4 <split [900/100]> Fold04 <tibble [2,200 × 6]> <tibble [0 × 3]>\n 5 <split [900/100]> Fold05 <tibble [2,200 × 6]> <tibble [0 × 3]>\n 6 <split [900/100]> Fold06 <tibble [2,200 × 6]> <tibble [0 × 3]>\n 7 <split [900/100]> Fold07 <tibble [2,200 × 6]> <tibble [0 × 3]>\n 8 <split [900/100]> Fold08 <tibble [2,200 × 6]> <tibble [0 × 3]>\n 9 <split [900/100]> Fold09 <tibble [2,200 × 6]> <tibble [0 × 3]>\n10 <split [900/100]> Fold10 <tibble [2,200 × 6]> <tibble [0 × 3]>\n```\n\n\n:::\n\n```{.r .cell-code}\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n12.621 sec elapsed\n```\n\n\n:::\n:::\n\n\nNow allow use of parallel processing (the default).  No plan is needed here (consistent with findings for `foreach()`).  Yay!\n\n::: {.cell}\n\n```{.r .cell-code}\ntic()\nlinear_reg(penalty = tune(), mixture = tune()) %>% \n  set_engine(\"glmnet\") %>% \n  tune_grid(preprocessor = rec, \n            resamples = splits, grid = tune_grid, \n            metrics = metric_set(rmse))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Tuning results\n# 10-fold cross-validation using stratification \n# A tibble: 10 × 4\n   splits            id     .metrics             .notes          \n   <list>            <chr>  <list>               <list>          \n 1 <split [900/100]> Fold01 <tibble [2,200 × 6]> <tibble [0 × 3]>\n 2 <split [900/100]> Fold02 <tibble [2,200 × 6]> <tibble [0 × 3]>\n 3 <split [900/100]> Fold03 <tibble [2,200 × 6]> <tibble [0 × 3]>\n 4 <split [900/100]> Fold04 <tibble [2,200 × 6]> <tibble [0 × 3]>\n 5 <split [900/100]> Fold05 <tibble [2,200 × 6]> <tibble [0 × 3]>\n 6 <split [900/100]> Fold06 <tibble [2,200 × 6]> <tibble [0 × 3]>\n 7 <split [900/100]> Fold07 <tibble [2,200 × 6]> <tibble [0 × 3]>\n 8 <split [900/100]> Fold08 <tibble [2,200 × 6]> <tibble [0 × 3]>\n 9 <split [900/100]> Fold09 <tibble [2,200 × 6]> <tibble [0 × 3]>\n10 <split [900/100]> Fold10 <tibble [2,200 × 6]> <tibble [0 × 3]>\n```\n\n\n:::\n\n```{.r .cell-code}\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n8.458 sec elapsed\n```\n\n\n:::\n:::\n\n\n\n## Final notes\n\nThe following is often found as an alternative setup for a back-end for parallel processing.  It works for `future_map()` (when combined with plan) and for `foreach()` but not in the tidymodels implementations of resampling.  Not clear why since those use `foreach()` but this should  not be used if you plan to use tidymodels resampling.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(doFuture)\nregisterDoFuture()\n```\n:::\n\n\nI tried this both directly and with various options of `plan()` \n\n::: {.cell}\n\n```{.r .cell-code}\nplan(multisession, workers = parallel::detectCores(logical = FALSE))\n```\n:::\n\n\nand with \n\n::: {.cell}\n\n```{.r .cell-code}\ncl <- makeCluster(parallel::detectCores(logical = FALSE))\nplan(cluster, workers = cl)\n```\n:::\n\n\n## Conclusions\n\nFor `future_map()`, `foreach()`, and tidymodels functions in parallel, set up the parallel backend with this code chunk.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncl <- parallel::makePSOCKcluster(parallel::detectCores(logical = FALSE))\ndoParallel::registerDoParallel(cl)\n```\n:::\n\n\nNothing further is needed to use `foreach()` or tidymodels functions.\n\nFor `future_map()`, you need to set up a multisession plan with this code chunk\n\n::: {.cell}\n\n```{.r .cell-code}\nplan(multisession, workers = parallel::detectCores(logical = FALSE))\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}